[ { "title": "Rust Receipe", "url": "/posts/rust-receipe/", "categories": "Rust", "tags": "Rust", "date": "2024-03-26 16:03:00 +0800", "snippet": "开启Cargo Bench 截至目前(1.78)必须在nightly环境里使用: rustup override set nightly 在需要使用bench的mod里放置下面两行代码: #![feature(test)]extern crate test; bench代码示例: #[bench]fn bench(b: &amp;mut Ben...", "content": "开启Cargo Bench 截至目前(1.78)必须在nightly环境里使用: rustup override set nightly 在需要使用bench的mod里放置下面两行代码: #![feature(test)]extern crate test; bench代码示例: #[bench]fn bench(b: &amp;mut Bencher){ b.iter(||{ ... })} 模拟函数重载Rust没有函数重载，但我们可以通过Trait来模拟pub trait Foo&lt;Args&gt; { fn invoke(&amp;self, args: Args);}struct FooImpl;impl Foo&lt;i32&gt; for FooImpl { fn invoke(&amp;self, i: i32) { println!(\"i32: {}\", i); }}impl Foo&lt;String&gt; for FooImpl { fn invoke(&amp;self, s: String) { println!(\"String: {}\", s); }}impl Foo&lt;(i32, i64)&gt; for FooImpl { fn invoke(&amp;self, t: (i32, i64)) { println!(\"Tuple: {:?}\", t); }}impl Foo&lt;()&gt; for FooImpl { fn invoke(&amp;self, _: ()) { println!(\"Unit\"); }}#[cfg(test)]mod tests { use super::*; #[test] fn test() { let foo = FooImpl; foo.invoke(42); foo.invoke(\"Hello, World\".to_string()); foo.invoke((42, 62)); foo.invoke(()); }}" }, { "title": "Meltdown攻击", "url": "/posts/meltdown/", "categories": "security", "tags": "", "date": "2024-03-03 17:13:00 +0800", "snippet": "今天和群友聊天的时候知道了Meltdown attack/spectre这种奇妙的侧信道攻击手法。利用这种手法，任意的进程都可以得到物理内存中的任意内容，可以轻易地得到内核中的敏感信息。什么是侧信道攻击什么是侧信道攻击？侧信道是指你的程序在正常的通信渠道以外，产生了某些其他的特征，而攻击者从这些特里拿到了你不想暴露的信息。这个“其他的特征”产生的信息通道就是侧信道。举个例子，假设你正在破解一...", "content": "今天和群友聊天的时候知道了Meltdown attack/spectre这种奇妙的侧信道攻击手法。利用这种手法，任意的进程都可以得到物理内存中的任意内容，可以轻易地得到内核中的敏感信息。什么是侧信道攻击什么是侧信道攻击？侧信道是指你的程序在正常的通信渠道以外，产生了某些其他的特征，而攻击者从这些特里拿到了你不想暴露的信息。这个“其他的特征”产生的信息通道就是侧信道。举个例子，假设你正在破解一个保险箱的密码，从正常的通信渠道来说你只能暴力破解，逐个尝试，但是当你破解第一位密码时，你发现旋钮到了4会有一些微弱的不一样的响声，那么可以有理由猜测第一位密码是4，这个例子里“旋钮是否发出异响”就是一个侧信道，通过它攻击者得到了保险箱的密码。Meltdown的攻击原理CPU运行的时候，不可避免的，总是要从内存中取数据的，而内存相对与CPU很慢，为了避免取数据时CPU空等，CPU工程师就发明了指令预取技术。假设有一个程序长下面这样：if (MEM == 0):\tinstructionA;MEM == 0不一定成立，若MEM == 0不成立，站在软件的层面来想，instructionA不应该被执行，但是由于指令指令预取技术的存在，CPU会“抢跑”，提前将instructionA执行了，如果MEM == 0成立，那就可以直接继续执行instructionA之后的指令；不成立的话CPU需要回滚把instructionA造成的影响撤销。另外，由于cache的存在，以及缓存局部性的问题，在同一时刻不同内存地址的访问速度并不均匀，也就是latency并不相同。meltdown就是利用了latency这一信息来获取敏感信息的，非常得具有想象力。例如我想攻击某一个对象，要得到其中某个地址ptr中的内容，我只需要设法和攻击对象共享一个数组A，然后诱导攻击对象利用ptr的内容data作为下标访问这个数组，那么由于之前访问过A[data]了，再次访问到A[data]的时候latency会更低。根据上面的原理，我们可以构造以下的攻击内核的meltdown程序：raise_exception();access A[*ptr]; // ptr就是我对攻击对象感兴趣的地址, A则是我这个进程里的一个内容按理来说，ptr对于攻击程序的进程来说可能是一个非法的地址，操作系统会阻止它访问，并且前面有raise_exception这个函数会引发一个异常，按理来说更不应该执行到下面这个语句。但是，由于预取的存在，CPU提前读了ptr里的内容，那么我再次逐个访问A里的元素，发现有某一个元素的访问延迟特别低，于是乎我们就知道ptr里的内容是多少了。想要知道某个地址对应的字节是什么，A只需是一个长度为256的数组即可。多么可怕又有想象力的攻击手段。要利用这个特性，需要CPU在预测失败的时候不仅将寄存器回滚，还需要将Cache也回滚Reference 15分钟读懂英特尔熔断幽灵漏洞 给程序员解释Spectre和Meltdown漏洞" }, { "title": "GreptimeDB Heartbeat机制详解", "url": "/posts/greptime-heartbeat/", "categories": "GreptimeDB", "tags": "WIP 🚧, GreptimeDB, Heartbeat", "date": "2023-12-28 16:14:00 +0800", "snippet": "本文将讲解greptimedb内部的heartbeat机制。首先看看官网Developer guide的介绍： Heartbeat Task is used to send heartbeat to the Metasrv. The heartbeat plays a crucial role in the distributed architecture of GreptimeDB an...", "content": "本文将讲解greptimedb内部的heartbeat机制。首先看看官网Developer guide的介绍： Heartbeat Task is used to send heartbeat to the Metasrv. The heartbeat plays a crucial role in the distributed architecture of GreptimeDB and serves as a basic communication channel for distributed coordination. The upstream heartbeat messages contain important information such as the workload of a Region. If the Metasrv has made scheduling(such as Region migration) decisions, it will send instructions to the Datanode via downstream heartbeat messages.Overview可以看到在greptimedb中Heartbeat分两个方向upstream和downstream，并且Datanode和Frontend都会向Meta Server发送心跳。upstream是datanode上报region信息到meta srv，downstream方向是meta srv主动向datanode发起调度。Datanode的Heartbeat主要逻辑位于：datanode/src/heartbeat.rs里。核心是HeartbeatTask。在Datanode启动的时候，HeartbeatTask随之start，并且Datanode会传入其region_event_receiver和leases_notifier给HeartbeatTask。region_event_receiver接收RegionServerEvent，也就是region的Registered和Deregistered两个事件，因为Heartbeat上报的是RegionStat，故Region发生了Registered和Deregistered时，自然需要做出对应的逻辑调整。HeartbeatTask的创建逻辑位于HeartbeatTask::try_new中。首先是创建了一个region_alive_keeper。这个东西非常重要，首先看看源码里的文档是怎么说的：/// [RegionAliveKeeper] manages all [CountdownTaskHandle]s.////// [RegionAliveKeeper] starts a [CountdownTask] for each region. When the deadline is reached,/// the status of region be set to \"readonly\", ensures there is no side-effect in the entity system.////// The deadline is controlled by the meta server. Datanode will send its opened regions info to meta sever/// via heartbeat. If the meta server decides some region could be resided in this Datanode,/// it will renew the lease of region, a deadline of [CountdownTask] will be reset.核心意思就是说：region_alive_keeper为每个region维护了一个倒计时任务，一旦这个任务被执行，region就变成readonly状态（不知道和memtable的frozen有没有关系）。heartbeat时会上报所有open的region的RegionStat，如果meta srv认为这个region能继续存活，就会刷新这个region的lease，也就是重置倒计时。RegionAliveKeeper有一个epoch，指的是该RegionAliveKeeper创建的时间，刷新region的lease的时候会以这个epoch为基准进行计算(RegionAliveKeeper作为HeartbeatResponseHandler的行为)；发送HearbeatRequest的时候也以epoch作为基准，计算当前时间和epoch的偏移量duration_since_epoch并放在Request里上报。然后是创建一个resp_handler_executor，这里resp_handler_executor的核心是一个Arc&lt;dyn HeartbeatResponseHandler的vec，包了一层抽象叫HandlerGroupExecutor，接收到resp以后就遍历执行这组HeartbeatResponseHandler。创建HeartbeatTask阶段比较trivial的解析options之类的逻辑就不再赘述了，不过值得注意的是HeartbeatTask还取了创建任务的时间并记录在node_epoch字段里。HeartbeatTask的启动创建完以后就进行HeartbeatTask的启动了。启动的核心逻辑如下：首先判断一下当前task是否已经启动过了，避免重复启动。然后取一大堆interval,node_id,node_epoch,addr,meta_client 之类的数据,并创建了一个逻辑上可以称为outgoing的管道。用outgoing_tx创建了一个HeartbeatMailbox。用前面获取的数据创建了一个和meta_srv之间的heartbeat stream，并且获取一个能通过该stream发送Heartbeat的HeartbeatSender称之为tx,而创建stream时做了什么这里按下不表，后面再说。取得了tx以后，启动了region_alive_keeper`。然后创建了一个死循环，循环的逻辑如下： 判断当前任务是否被关闭了，是就退出 否则，tokio::select三件事： 要么从outgoing这个channel中收到一个message，把这个MailboxMessageencode成一个HeartbeatRequest 于是有一个这样的数据流mailbox-&gt;tx-&gt;meta srv mailbox的数据来源 对IncomingMessage（也就是Meta srv对Datanode发出的Instruction）对应的响应(OutgoingMessage=MessageMeta+InstructionReply) 要么睡够了interval这么长的时间(第一次进循环时不睡，直接进这个事件)，收集所有opened_region的region_stat，构造HeartbeatRequest 要么收到了quit_signal，构造一个dummy heartbeat request，通过后续发送重新建立heartbeat stream。 通过tx(HeartbeatSender)发送上一步构造的HeartbeatRequst,如果发送出现错误，尝试重新建立heartbeat stream HeartbeatStream 上文提到了在启动HeartbeatTask的时候会通过create_streams这个函数创建一个heartbeat stream，通过heartbeat stream进行meta srv和datanode之间心跳包的双向通讯。这个heartbeat stream的tx端如何使用上文已经说过了，而create_streams中则创建了datanode处理rx端的死循环，循环就是不断处理来自meta srv的包，数据包可能是mailbox incoming message，也可能是普通的region_lease刷新message，处理时会对这些数据包做些信息收集工作(打info log或者收集到metric里)，然后就是让前文的handler_executor处理这些包，最后如果上文的lease_notifier存在，那就notify一下。上面都是正确运行时的循环逻辑，如果从rx端接收数据包的时候发生错误了，那循环就退出了，并且向quit_signal中发送信号，表明当前流被断开。上面是rx端处理的逻辑。通过前面的综合分析，可以得到下面的图，datanode和MetaSrv可以双向通讯，并非简单的C/S模式： 而建立stream的逻辑实际上在meta_client.heartbeat()中，meta_client.heartbeat()转到了heartbeat_client().heartbeat()里，这里可以参考[[MetaClient]]。heartbeat_client().hearbeat()第一步是ask_leader，其流程是获取当前的leadership_group的所有peers后shuffle之，再遍历一趟，向每个peer发送AskLeaderRequest，得到leader以后，向leadership_group写入leader信息。第二步是真正的inner.heartbeat()，逻辑如下： 构造一个连接到leader的client 构造用于发送请求的mpsc::channel::&lt;HeartbeatRequest&gt;(128)(这应该是tonic这个框架里的某种idiom) let (sender, receiver) = mpsc::channel::&lt;HeartbeatRequest&gt;(128);sender.send(handshake).await.map_err(|e| {...});let receiver = ReceiverStream::new(receiver);let mut stream = leader .heartbeat(receiver) .await// 后续发送请求只要往sender里send就行了，不用关心别的 构造包含当前节点node_id和role端的RequestHeader 构造一个起握手作用的HeartbeatRequest，并用sender发送之 构造和leader之间的stream 获取上面的请求响应，错误了就处理错误 包装上面管道的sender为请求sender，包装stream为receiverMeta Server对HeartbeatRequest的处理纵览逻辑首先找到最关键的trait,HeartbeatHandler。#[async_trait::async_trait]pub trait HeartbeatHandler: Send + Sync { fn is_acceptable(&amp;self, role: Role) -&gt; bool; fn name(&amp;self) -&gt; &amp;'static str { let type_name = std::any::type_name::&lt;Self&gt;(); // short name type_name.split(\"::\").last().unwrap_or(type_name) } async fn handle( &amp;self, req: &amp;HeartbeatRequest, ctx: &amp;mut Context, acc: &amp;mut HeartbeatAccumulator, ) -&gt; Result&lt;HandleControl&gt;;}看到这里就能猜到大概的结构就是有一个总的handler，然后根据不同Heartbeat的类型将其分发给具体的handler（策略模式） 。总的handler在impl heartbeat_server::Heartbeat for MetaSrv里，heartbeat_server::Heartbeta这个trait定义核心逻辑非常简单：pub trait Heartbeat {\ttype HeartbeatStream;\tfn heartbeat(&amp;self, tonic::Request&lt;tonic::Streaming&lt;...&gt;&gt;)-&gt;...;\tfn ask_leader(&amp;self, request: tonic::Request&lt;AskLeaderRequest&gt;)-&gt;...;}MetaSrv的heartbeat也非常简单，核心是一个循环，不断得从stream里取出request，进行以下操作： 解析request，首先match看看是不是一个合法的request，不然进错误处理(Err分支) 取出header，没有header就报错 如果pusher_key是None 取出node_id，注意，datanode和frontend的heartbeat都是走这个处理函数的，datanode的node_id是由datanode传递过来的member_id，虽然datanode传过来的id=(cluster_id, member_id)，但这里只用了member_id。而frontend则是一个metasrv内部的自增AtomicU64 取出role，也就是请求发送方到底是datanode还是frontend node_id和role拼成key，然后向handle_group里用这个key注册一个返回请求的pusher，handle_group里有一个从key到pusher的map，pusher用于主动向下游发送信息(MailboxMessage)，所以可以猜测，发送MailboxMessage的时候，收信方是以key来标识的，也就是HeartbeatMailbox::send里的pusher_id。 将pusher_key设为Some(key)，这里pusher_key不为None以后就不用再进这个分支，因为heartbeat时Client和Server之间是长连接的Stream，后面Client的key也不会变化，第一次handshake完了以后，就不需要重新构建链接，也就不需要再注册key及其对应的Pusher。(Frontend因为是无状态的，猜测其node_id会由第一次handshake从MetaSrv处分配后在Response里获得)。 于是整体数据的流动可以看成这样 使用HandlerGroup去handle这个request，并得到result 逻辑上HandlerGroup是一个HeartbeatHandler的Vec，不过有点小细节的是，实际用的是NameCachedHandler这个包装，其作用是缓存了HeartbeatHandler.name()的结果，避免每次都对这个常量去求值(这里name等于实际的struct type name) HandlerGroup::handle遍历所有handler，一边遍历一边把中间结果存到HeartbeatAccumulator中，每个handler返回Continue或者Done，返回Done说明这个请求已经处理完了，直接跳出循环，然后把accmulator的内容提取并返回 HandlerGroup里还有pushers 根据result判断当前stream连接的还是不是leader,如果已经不是leader了，主动断开当前的stream 断开stream的时候将第3步注册的pusher给unregister掉 每个handler的逻辑CollectStatsHandler 职责：负责收集HeartbeatRequest中的stat到accumulator.stat中。 接受请求来源：只接受来自datanode的Heartbeat，并且不处理MailboxMessage（MailboxMessage不会有stat）。 实现逻辑： 如果请求是MailboxMessage，直接返回Continue。 尝试从Request中提取出Stat，成功提取了就将stat插入accumulator.stat，失败了打一条警告信息 返回Continue CheckLeaderHandler 职责：判断当前MetaSrv是否仍是Leader 接受请求来源：只接受来自datanode的Heartbeat。 实现逻辑： 如果当前context里没有election模块(没有可能是单节点模式)，直接返回Continue 用上面获取到的election模块判断当前metasrv是否是leader，是leader可以直接返回Continue 不是leader就在Response的header里写入错误信息Error::is_not_leader() 返回Done，因为当前节点不是leader的话，后面的handler也没有必要再继续做了 KeepLeaseHandler 职责：维护每个节点上次续租的时间，也就是node到lease的KV对 接受请求来源：datanode 实现逻辑： 取出Request的header和peer(请求来自谁)，没有直接返回 拼出lease_key:(cluster_id,node_id) 拼出lease_value：当前的时间戳（语义为上次活动时间）和peer的地址 把上面的key和value转成字节数组(Vec&lt;u8&gt;)，写入存储元数据的KV库。这里写入的是ResettableKvBackend，没有进行持久化 返回Continue RegionLeaseHandler 核心逻辑 取出stat的所有regions及其所在的cluster_id和datanode_id 刷新每个cluster_id,datanode_id和region_id构成的三元组对应的lease；返回不存在的region以及成功刷新的region有哪些(注意region_id和role才构成一个完整的region描述符) 成功刷新lease的regions集合转成GrantedRegion的vector PersistStatsHandler 接受请求来源：datanode 具体实现逻辑： 取出accumulator里的stat，没有就直接返回 取stat的stat_key(同样是(cluster_id, node_id)) PersistStatsHandler内有一个StatKey-&gt;EpochStats的DashMap，称为stats_cache EpochStats=Optional Epoch + Vector of Stat 取出stat_cache里记录的epoch_stat，没有就插个默认的 判断是否需要刷新epoch 如果epoch_stat里存在epoch,如果current_stat传过来的node_epoch更大就更新，并且清空之前记录的所有stat(因为这意味着node可能重新deploy了，node_epoch发生了改变);node_epoch更小就是接收到了过期的heartbeat，那么忽略，并警告；如果node_epoch和epoch相等，则是正常的 如果epoch_stat里不存在epoch，毫无疑问，直接设置current_stat里传过来的node_epoch作为epoch 向epoch_stat中插入current_stat 如果之前判断不需要刷新epoch，那么只需要判断epoch_stats里记录的stat数量是否小于阈值MAX_CACHED_STATS_PER_KEY，小于就返回Continue 否则，需要持久化epoch_stats了，把epoch_stats的所有stats拎出来(drain_all)然后写到in_memory的KV里 结论： stats做了一个多阶段的Cache，首先在Hadler里按(cluster_id,node_id)作为key，维护了一个记录对应的stats的局部cache，用epoch来判断当前的stats是否仍然合法；写满了就写到全局的in_memory键值存储里，缓解全局in_memory存储的压力 Datanode对HeartbeatResponse的处理" }, { "title": "数据库领域会议和期刊合集", "url": "/posts/database-conference/", "categories": "Database Research", "tags": "", "date": "2023-12-28 15:22:00 +0800", "snippet": "以下是一些数据库相关领域的会议以及期刊会议A类会议 VLDB - Very Large Data Bases CIDR - Conference on Innovative Data Systems Research SIGMOD - Special Interest Group on Management of Data ICDE - The International Counc...", "content": "以下是一些数据库相关领域的会议以及期刊会议A类会议 VLDB - Very Large Data Bases CIDR - Conference on Innovative Data Systems Research SIGMOD - Special Interest Group on Management of Data ICDE - The International Council for Open and Distance Education OSDI - Operating Systems Design and Implementation FAST - File and Storage TechnologiesB类会议 EDBT - Extending Database Technology ICDT - The International Conference on Database Theory DASFAA - Database Systems for Advanced Applications期刊A类期刊 VLDBJ - VLDB基金会主管的期刊 TKDE - IEEE Transactions on Knowledge and Data EngineeringB类期刊 TKDD - Transactions on Knowledge Discovery from Data" }, { "title": "泛型在Go中的应用", "url": "/posts/go-generics/", "categories": "Go", "tags": "Generics, Error Handling", "date": "2022-03-22 20:08:00 +0800", "snippet": "Go1.18正式发布，从此Go算是正式有了泛型，本文来探讨Go泛型的几种应用场景。类型安全的函数式接口在Go语言里，函数是一等公民，这意味着你可以进行一定程度的函数式编程，但是因为Go拉胯的类型系统以及Lambda表达式的缺位，Go做起函数式编程来总是不太舒服，现在有了参数化类型以后map，fold，filter等函数总算是能舒服些了。接下来看看如何利用泛型实现出类型安全的Map， Filt...", "content": "Go1.18正式发布，从此Go算是正式有了泛型，本文来探讨Go泛型的几种应用场景。类型安全的函数式接口在Go语言里，函数是一等公民，这意味着你可以进行一定程度的函数式编程，但是因为Go拉胯的类型系统以及Lambda表达式的缺位，Go做起函数式编程来总是不太舒服，现在有了参数化类型以后map，fold，filter等函数总算是能舒服些了。接下来看看如何利用泛型实现出类型安全的Map， Filter， Foldl，Foldr。实现从这几个函数的类型签名入手，然后按语义进行翻译就是了： 这里类型签名采用我偏爱的Haskell的类型签名（同时混合使用了Go的类型），个人认为这种记法的好处在于分离了identifier和type signature，便于一眼看出函数的类型以及进行类型的运算；这种记法里的-&gt;可以理解为一个映射 Map :: (A -&gt; B) -&gt; []A -&gt; []B 对应的Go实现: func Map[A, B any](f func(A) B, l []A) []B { res := make([]B, len(l)) for i, e := range l { res[i] = f(e) } return res} Filter :: (A -&gt; bool) -&gt; []A -&gt; []A 对应的Go实现: func Filter[A any](f func(A) bool, l []A) []A { res := make([]A, 0, len(l)) for _, e := range l { if f(e) { res = append(res, e) } } return res} Foldl :: (B -&gt; A -&gt; B) -&gt; B -&gt; []A -&gt; B 对应的Go实现 func Foldl[A, B any](f func(B, A) B, b B, l []A) B { res := b for _, e := range l { res = f(res, e) } return res} Foldr :: (A -&gt; B -&gt; B) -&gt; B -&gt; []A -&gt; B 对应的Go实现 func Foldr[A, B any](f func(A, B) B, b B, l []A) B {\tres := b\tfor i := len(l) - 1; i &gt;= 0; i-- {\t\tres = f(l[i], res)\t}\treturn res} ForEach :: (A -&gt; Unit) -&gt; []A -&gt; Unit 这里Unit用来表示无返回 对应的Go实现 func ForEach[A any](f func(A), l []A) {\tfor _, e := range l {\t\tf(e)\t}}借助上面这些基本函数可以实现出:concat，concatMapfunc Concat[A any](l [][]A) []A {\treturn Foldl(func(a []A, b []A) []A { return append(a, b...) }, []A{}, l)}func ConcatMap[A, B any](f func(A) []B, l []A) []B { return Concat(Map(f, l))}应用比较常见的简单应用就不说了，例如Web开发中可以利用Map方便地进行Vo,Dto,Entity之间的转换。这里给几个比较fancy的例子： 全排列函数(这里假设列表里没有重复元素了，为了Remove实现方便一点)func Remove(x int, l []int) []int {\treturn Filter(func(y int) bool { return x != y }, l)}func Permutations(s []int) [][]int {// 如果s是个空集合，那么其全排列为一个包含空集合的集合，即{Ф}\tif len(s) == 0 {\t\treturn [][]int{[]int{}}\t}/* 这个ConcatMap是精髓，先看ConcatMap的对象，就是s，所以对每个元素都会执行第一个函数参数 * 第一个函数的意思是：接受元素x，然后把集合s中的x去除以后对剩下的部分进行全排列， * 然后向得到的全排列集合里的每个切片的最后上插一个x * 如此一来就得到了以x为尾其余元素的一个全排列为头的集合的集合； * 对s中的每个元素都应用这个函数然后再拼接不就得到了所有元素的全排列 * 当然这个实现是满出翔并且有bug的 */\treturn ConcatMap(func(x int) [][]int {\t\treturn Map(func(p []int) []int { return append(p, x) }, Permutations(Remove(x, s)))\t}, s)} 求解八皇后func abs(x int) int {\tif x &lt; 0 {\t\treturn -x\t}\treturn x}func safe(k int, positions []int) bool {\tfor i, p := range positions {\t\tif p == k || abs(p-k) == i+1 {\t\t\treturn false\t\t}\t}\treturn true}func sequence(a, b int) []int {\tif a &gt; b {\t\treturn []int{}\t}\tresult := make([]int, b-a+1)\tfor i := range result {\t\tresult[i] = a + i\t}\treturn result}func positions(k, n int) [][]int {//positions: 尝试在大小为n的棋盘的第k行放棋子\tif k == 0 {\t\treturn [][]int{[]int{}}\t}\tconf := positions(k-1, n) /* * 稍微解释一下这坨怪物，其实懂了以后就明白这是个非常简洁的回溯 * 首先看ConcatMap的对象，sequence(1, n)，其实就是对于从1..n这n个位置，循环使用第一个函数 * 可以展开成对应的for循环 * 然后Map的效果是在对头上插上p * Filter过滤出那些在p上放置棋子仍然安全的情况(这样就会边搜索边剪枝了) */\treturn ConcatMap(func(p int) [][]int {\t\treturn Map(func(ps []int) []int { return append([]int{p}, ps...) },\t\t\tFilter(func(ps []int) bool { return safe(p, ps) }, conf))\t}, sequence(1, n))}func Queen(boardSize int) [][]int {\treturn positions(boardSize, boardSize)}与Go泛型相关内容，计划下一篇更新迭代器模式" }, { "title": "词法分析之NFA, DFA, Min-DFA与RE, RG", "url": "/posts/FSA_and_RE/", "categories": "编译原理, 词法分析", "tags": "自动机理论, Finite State Automata", "date": "2022-03-02 23:52:00 +0800", "snippet": " Computation with automata.Glossary NFA: Non-Deterministic Finite Automata 非确定性的有限状态自动机 对于NFA的非确定, 有两种有趣的解释 在需要做出不确定选择的时候, NFA会复制自己并执行所有的操作, 如果最终有任何一台自动机到达了接收状态, 那么NFA接收...", "content": " Computation with automata.Glossary NFA: Non-Deterministic Finite Automata 非确定性的有限状态自动机 对于NFA的非确定, 有两种有趣的解释 在需要做出不确定选择的时候, NFA会复制自己并执行所有的操作, 如果最终有任何一台自动机到达了接收状态, 那么NFA接收这个输入 在需要做出不确定选择的时候, NFA的选择总是正确, 也就是说, 只要这个串是能被接收的, 那NFA一定能选对 DFA: Deterministic Finite Automata 确定性的有限状态自动机 Min-DFA: Minimal Deterministic Finite Automata 最小的DFA RE: Regular Expression 正则表达式 RG: Regular Grammar 正则文法NFA,DFA,Min-DFA,RE的关系一般地，认为NFA, DFA, Min-DFA, RE的关系如下graph LRA[NFA]B[DFA]D[RE]E([code for a scanner])A--Subset Construction--&gt;B--Kleene's Construction--&gt;D--Thompson's Construction--&gt;AB--DFA Minimization--&gt;BA--&gt;ED--Direct method--&gt;BDFA Minimization有两种算法: Brzozowski, Hopcroft.RE to NFA: Thompson Construction先看正则表达式的结构, 这里就不那么形式化了, 用Haskell的语法写了=_=data RegExp = Symbol Char -- Basic Character a | Concat RegExp RegExp -- Concatenation ab | Union RegExp RegExp -- Union a+b | Star RegExp -- Kleene star a* 当RegExp是Symbol a时 stateDiagram-v2\tdirection LR\ts0\ts1\t[*]--&gt;s0\ts0--&gt;s1:a\ts1--&gt;[*] 当RegExp是Concat e1 e2时 stateDiagram-v2\tdirection LR\t%% e1--&gt;e2:ε\ts1--&gt;s3:ε\tstate e1{\t\tdirection LR\t\t[*]--&gt;s0\t\ts0--&gt;s1\t}\tstate e2{\t\tdirection LR\t\ts3--&gt;s4\t\ts4--&gt;[*]\t} 或者 stateDiagram-v2\tdirection LR s1:公共结点 s0--&gt;s1 s1--&gt;s2\tstate e1{\t\tdirection LR\t\t[*]--&gt;s0\t}\tstate e2{\t\tdirection LR\t\ts2--&gt;[*]\t} 当RegExp是Union e1 e2时 stateDiagram-v2\tdirection LR\t[*]--&gt;s0\ts0--&gt;s1:ε\ts0--&gt;s3:ε\ts2--&gt;s5:ε\ts4--&gt;s5:ε\ts5--&gt;[*]\tstate e1{\t\tdirection LR\t\t\ts1--&gt;s2\t}\tstate e2{\t\tdirection LR\t\t\ts3--&gt;s4\t} 当RegExp是Star e时 stateDiagram-v2\tdirection LR\t[*]--&gt;s0\ts0--&gt;s1:ε \t\ts2--&gt;s3:ε\ts3--&gt;[*] s0--&gt;s3:ε\tstate e{\t\tdirection LR\t\ts1--&gt;s2\t\ts2--&gt;s1:ε\t} 做题的时候一定不要图省事, 省略某些步骤; 严格按照这四个pattern来, 会让你避免很多麻烦NFA to DFA: 子集构造法子集构造法有两个重要的函数 $\\text{Move}(s_i, a)$, 返回从状态$s_i$接收输入$a$能到达的状态集合 $\\text{FollowEpsilon}(s_i)$, 返回从状态$s_i$接收$\\epsilon$能到达的状态集合, 包括$s_i$本身和经过多次空转移到达的状态用自然语言描述这个算法就是: 从NFA的起始状态$n_0$构造出DFA的起始状态$d_0$ $d_0 = \\text{FollowEpsilon}({n_0})$ 令$D = {d_0}$ 对所有$\\alpha\\in \\Sigma$, 计算$\\text{FollowEpsilon}(\\text{Move}(d_0, \\alpha))$ 如果这一步算出了新状态, 将其加入$D$ 遍历$D$, 对每个状态计算$\\text{FollowEpsilon}(\\text{Move}(d_0, \\alpha))$, 直到没有新状态产生为止 子集构造法也涉及到不动点问题. 用伪代码则是:\\[\\begin{align*}&amp;d_0 \\leftarrow \\text{FollowEpsilon}({n_0}) \\\\&amp;D \\leftarrow \\{d_0\\} \\\\&amp;W \\leftarrow \\{d_0\\} \\\\&amp;\\text{while }(W \\ne \\emptyset)\\ \\{ \\\\ &amp;\\quad\\text{从}W\\text{里随便选择并删除一个元素}s\\\\ &amp;\\quad\\text{for each } \\alpha \\in \\Sigma\\ \\{ \\\\ &amp;\\quad\\quad t \\leftarrow \\text{FollowEpsilon}(\\text{Move}(s, a))\\\\ &amp;\\quad\\quad T[s, \\alpha]\\leftarrow t \\\\ &amp;\\quad\\quad \\text{if }(t \\notin D) \\text{ then \\{}\\\\ &amp;\\quad\\quad\\quad \\text{向}D\\text{里添加}t\\\\ &amp;\\quad\\quad\\quad \\text{向}W\\text{里添加}t\\\\ &amp;\\quad\\quad\\}\\\\ &amp;\\quad\\}\\\\&amp;\\}\\end{align*}\\]容易知道, 子集构造法本质上就是合并了不同状态的相同前缀, 因为在DFA里的每个状态都是由NFA里的一个状态$s_i$经过空串或一个字母$\\alpha$迁移过来的.DFA to Minimal DFA状态机里可能存在冗余的状态, 也是说有多个状态无法找到一个输入串区分它们, 形式化的描述是:\\[s_i\\text{和}s_j\\text{是等价状态} \\Leftrightarrow \\forall c\\in \\Sigma, T(s_i, c) = T(s_j, c) \\land \\text{Path}(s_0, s_i) = \\text{Path}(s_0, s_j)\\]Brzozowski’s algorithm核心想法: 既然子集构造法能合并相同前缀的状态, 那我能不能再利用子集构造法合并冗余状态呢? 冗余就是那些前缀相同和后缀相同的状态, 那么我把状态机翻过来做一次子集构造法不就能合并后缀, 再翻过来做一次子集构造法不就把前缀也合并了.基于上面这个想法, Brzozowski设计了如下的算法进行DFA的最小化. 将NFA翻转过来, 得到NFA’ 对NFA’执行子集构造法得到DFA’, 此时完成了后缀合并, 但这个时候自动机是反的 将DFA’翻转过来得到NFA’’, 对NFA’‘进行子集构造法, 就完成了前缀的合并, 并且自动机也翻回正向的了翻转自动机的方法: 将原自动机的边翻转, 原自动机的起始状态成为终止状态, 原自动机的终止状态成为起始状态, 如果原自动机有多个终止状态那就新增一个状态$s_e$, 所有原终止状态通过$\\epsilon$转移到$s_e$即可继续翻转.Hopcroft’s algorithm核心想法: Hopcroft的想法更直接, 基本的idea就是: 最小化DFA不就是把等价的状态划分到一起, 那不就是找原状态机里的一个划分, 把等价的状态放到一起, 划分的每个组内的状态相互不可区分, 然后用这个划分组成新的自动机.我们希望这个划分应该有什么性质才能保证DFA是最小的呢? 假定最后的划分是$P={p_0, p_1, p_2, \\dots p_n}$, $P$应该有这样的性质: 如果$d_i, d_j \\in p_s$并且如果有$c$使得$d_i\\to d_x, d_j\\to d_y$, 那么$d_x, d_y\\in p_t$ 如果$d_i, d_j \\in p_s$并且$d_i\\in F$, 那么$d_j\\in F$($F$是接收状态集合)具体的运算过程: 先乐观地将所有状态划分为两个组: 接收状态组和其他状态组, (这是因为我们希望最终得到的划分组数最少) 从当前划分中任意选取一个状态组, 检查是否存在一个字母$c$使得组内的状态迁移到不同的组内, 如果存在那就按照这些迁移将该组进行划分, 使得划分后的一个状态组内的每个状态在字母$c$下都迁移到同一个组内. 重复执行该步骤直到无法根据某个字母对任何一个组进行分割为止.伪代码:\\[\\begin{align*}&amp;worklist \\leftarrow \\{F, \\{D-F\\}\\} \\\\&amp;partition \\leftarrow \\{F, \\{D-F\\}\\} \\\\&amp;\\text{while }(worklist \\ne \\emptyset) \\text{ \\{} \\\\&amp;\\quad \\text{从}worklist\\text{中选取并移除一个状态组}S \\\\&amp;\\quad \\text{for each } \\alpha \\in \\Sigma \\text{ \\{} \\\\&amp;\\quad \\quad image \\leftarrow \\{x \\vert \\delta (x, \\alpha) \\in S \\} \\\\&amp;\\quad \\quad \\text{for each } q \\in partition \\text{ that has a state in image \\{} \\\\&amp;\\quad \\quad \\quad q_1 \\leftarrow q \\cap image \\\\&amp;\\quad \\quad \\quad q_2 \\leftarrow q - q_1 \\\\&amp;\\quad \\quad \\quad \\text{if } q_2 \\ne \\emptyset \\text{ \\{} \\\\&amp;\\quad \\quad \\quad \\quad \\text{从}partition\\text{中移除}q \\\\&amp;\\quad \\quad \\quad \\quad partition \\leftarrow partition \\cup q_1 \\cup q_2 \\\\&amp;\\quad \\quad \\quad \\quad \\text{if } q \\in worklist \\text{ \\{} \\\\&amp;\\quad \\quad \\quad \\quad \\quad \\text{从}worklist\\text{中移除}q \\\\&amp;\\quad \\quad \\quad \\quad \\quad worklist \\leftarrow worklist \\cup q_1 \\cup q_2 \\\\&amp;\\quad \\quad \\quad \\quad \\text{else } \\text{if } \\vert q_1 \\vert \\le \\vert q_2 \\vert \\text{ \\{} \\\\&amp;\\quad \\quad \\quad \\quad \\quad worklist \\leftarrow worklist \\cup q_1 \\\\&amp;\\quad \\quad \\quad \\quad \\text{else } \\\\&amp;\\quad \\quad \\quad \\quad \\quad worklist \\leftarrow worklist \\cup q_2 \\\\&amp;\\quad \\quad \\quad \\quad \\} \\\\&amp;\\quad \\quad \\quad \\quad \\text{if } s = q \\text{ \\{} \\\\&amp;\\quad \\quad \\quad \\quad \\quad break; \\\\&amp;\\quad \\quad \\quad \\quad \\} \\\\&amp;\\quad \\quad \\quad \\} \\\\&amp;\\quad \\quad \\} \\\\&amp;\\quad \\} \\\\&amp;\\} \\\\\\end{align*}\\]DFA to RE: Kleene’s construction定理: 如果$L=L(A)$是某DFA $A$的语言, 那么存在正则表达式$R$满足$L=L(R)$进行转换的基本idea: $R_{ij} = R_{ij}^{不经过k}+R_{ik}^{不经过k}(R_{kk}^{不经过k})^*R_{kj}^{不经过k}$ 定理及证明: 对DFA $A$的状态编号, 令1为开始状态, 即\\[A=(\\{1, 2, \\dots, n\\}, \\Sigma, \\delta, 1, F)\\] 设正则表达式$R_{ik}^{(k)}$表示从$i$到$j$但中间节点标号不超过$k$全部路径的字符串集合\\[R_{ij}^{(k)} = \\{ x | \\hat \\delta(i, x) = j, x经过的状态除两端外标号不超过k\\}\\] 那么与$A=({1, 2, \\dots, n}, \\Sigma, \\delta, 1, F)$等价的正则表达式为\\[\\bigcup_{j\\in F}R_{1j}^{(n)}\\] 且递归式为\\[R_{ij}^{(k)} = R_{ij}^{(k-1)} + R_{ik}^{(k-1)}(R_{kk}^{(k-1)})^*R_{kj}^{(k-1)}\\]\\[R_ij^{(0)} = \\begin{cases} \\{\\alpha | \\delta(q_i, \\alpha) = q_j\\} &amp; i\\ne j \\\\ \\{\\alpha | \\delta(q_i, \\alpha) = q_j\\} \\cup \\{\\epsilon\\} &amp; i = j \\\\ \\end{cases}\\] Base case: 当$i\\ne j, k = 0$时, 即$i$到$j$没经过任何中间结点 没有$i$到$j$的状态转移 graph LRi((i))j((j)) $R_{ij}^{(0)}=\\emptyset$ 有一个$i$到$j$的状态转移 graph LRi((i))j((j))i--a--&gt;j $R_{ij}^{(0)}=a$ 有多个$i$到$j$的状态转移 graph LRi((i))j((j))i--a--&gt;ji--b--&gt;ji--c--&gt;j $R_{ij}^{(0)}=a+b+c$ 当$i = j, k = 0$时, 即从$i$到自身没经过任何中间结点 状态$i$没有到自己的转移 graph LRi((i)) $R_{ii}^{(0)} = \\varepsilon$ 状态$i$有一个到自身的转移 graph LRi((i))i--a--&gt;i $R_{ii}^{(0)} = a + \\varepsilon$ 状态$i$有多个到自身的转移 graph LRi((i))i--a--&gt;ii--b--&gt;ii--c--&gt;i $R_{ii}^{(0)} = a + b + c \\varepsilon$ " }, { "title": "常用网站分类收藏", "url": "/posts/website_archive/", "categories": "网站分类收藏", "tags": "", "date": "2022-02-26 00:00:00 +0800", "snippet": " Frequently use website资源类 Google Scholar IEEE Xplore ACM Digital Library IACR’s ePrint archive DBLP arXiv CiteSeerX JSTOR SpringerLink Semantic Scholar Libgen SciHub大牛博客 包云岗的博客 美团技术...", "content": " Frequently use website资源类 Google Scholar IEEE Xplore ACM Digital Library IACR’s ePrint archive DBLP arXiv CiteSeerX JSTOR SpringerLink Semantic Scholar Libgen SciHub大牛博客 包云岗的博客 美团技术团队 Keep Coding Tech Explorer, 数据库, LinuxC 凝神长老 阮一峰 JR’s Blog Mthli JYY的WIKI 玄简君 Kaito, 中间件, 分布式系统的讲解非常不错Go语言 Go设计模式与Web开发等 Go Wiki Go语言高性能编程 菜刚(Golang系列)Java语言 BaeldungWSL WSL设置静态IP WSL里使用nvim如何共享剪贴板问题公开课 名校公开课程评价网 南大SICP 南大ICS PA CS4160 形式化验证 COMS W3157 Programming Language and Translators 南大静态分析 CMU静态分析 CS144 Introduction to Computer Networking JYY蒋神OS 国科大陈立前老师程序分析 熊英飞软件分析技术视频 熊英飞软件分析技术Slides 梁红瑾程序设计语言的形式语义 Stanford CS242 CS3520 Utah Cornell CS3110 MIT 6.824免费书籍 HTDP Crafting Interpreter 一份不太简短的LATEX2e介绍 OCaml Programming: Correct + Efficient + Beautiful Real World OCaml How To Ask Question Operating System: Three Easy Pieces Jeff Erickson的Algorithms How to Read a Paper工具网站 GodBolt 数据神厨 PasteBin 代码查重，MOSS 正则表达式转非确定性有穷自动机 正则表达式铁道图 自动机模拟器 Regex Debugger Overleaf 在线LaTex编辑器 Tables Generator 表格生成器 QuillBot Paraphrase 工具 Detexify 识别手写符号输出LaTex指令 Connected Papers 论文关联可视化 Academic Phrase Bank 一些模板句 doi2bib 把DOI转成BibTex Linggle 词汇搭配分析 Shapecatcher Unicode手写识别 Try It Online 各种编程语言在线运行MISC 如何在Markdown里使用PlantUML画图 Tmux 使用教程 一年成为Emacs高手 Mirage OS(Unikernel) JYY开发的代码查重吉他谱 夕凪" }, { "title": "通用的Memorization方法", "url": "/posts/memorize/", "categories": "SICP", "tags": "python, lisp", "date": "2021-04-23 16:58:00 +0800", "snippet": " 最近看到了一个scheme实现的通用记忆化方法，但其代码晦涩难懂，整理了一份python版本，发现远比lisp简单明了，遂写一篇博客保留之。1. Intro记忆法(Memorization)，或称表格法(tabulation)是一种常用的缓存技术，采用这种技术的函数将前面已经算出的一些值记录在一个局部的字典里，这种手段能够大大加快一些函数的效率。采用记忆法的过程维护着一个字典，其中保存着...", "content": " 最近看到了一个scheme实现的通用记忆化方法，但其代码晦涩难懂，整理了一份python版本，发现远比lisp简单明了，遂写一篇博客保留之。1. Intro记忆法(Memorization)，或称表格法(tabulation)是一种常用的缓存技术，采用这种技术的函数将前面已经算出的一些值记录在一个局部的字典里，这种手段能够大大加快一些函数的效率。采用记忆法的过程维护着一个字典，其中保存着前面已经做过的调用求出的值，以产生这些值的对应参数作为Key。当这种过程被调用时，它首先检查有关的字典，看看相应的值是否已经在那里，如果找到了，就直接返回这个值; 否则就以正常的方式计算出相应的值，并将这个值保存到表格里。举一个经典的例子:memo = {0: 0, 1: 1}# 不带记忆的版本def fib(n): if n == 0: return 0 if n == 1: return 1 return fib(n - 1) + fib(n - 2)## fib(30) time elapsed: 0.2773573199999999# 带记忆的版本def fib_memo(n): if n in memo: return memo[n] else: memo[n] = fib(n - 1) + fib(n - 2) return memo[n]## fib_memo(30) time elapsed: 4.91160000000157e-05容易知道不带记忆的函数计算较带记忆的函数慢很多。记忆法很不错，但是采用上述记忆法带来的缺点有: 需要修改函数的具体实现 要引入一个全局变量进行记忆 记忆的方法不通用2. Generalize针对以上三个缺点，我们来逐一解决。2.1 消除全局变量还是以斐波那契为例，memo的目的是记录函数运行的结果，要做到这一点不需要使用全局变量，只需要让我们的函数带上自由变量即可。def get_fib(): memo = {0: 0, 1: 1} def inner(n): if n in memo: return memo[n] else: memo[n] = inner(n - 1) + inner(n - 2) return memo[n] return innerfib = get_fib()## fib(30) time elapsed: 4.8156000000076915e-052.2 让记忆方法通用通过前面的修改，我们消除了全局变量。观察到inner中对memo进行了修改的只有一行memo[n] = inner(n - 1) + inner(n - 2)，这里可以抽象成为一个计算过程f，f可作为参数传入。根据这个idea我们得到了以下代码：def memorize(f):\tmemo = {}\tdef inner(n):\t\tif n not in memo:\t\t\tmemo[n] = f(n)\t\treturn memo[n]\treturn inner\tfib_memo_lambda = memorize(lambda x: 0 if x == 0 else 1 if x == 1 else fib_memo_lambda(x - 1)+fib_memo_lambda(x - 2))## fib_memo_lambda(30) time elapsed: 9.787600000010777e-05def fib(n): if n == 0: return 0 if n == 1: return 1 return fib(n - 1) + fib(n - 2)这样我们把记忆的过程抽象出来了，memorize就成为了一个通用的记忆方法。但是这个实现我们还是需要修改fib原来的实现，并且fib_memo这种利用lambda表达式的方法令人费解（It is actually a little tricky,具体tricky在哪儿，请看思考题），能不能再优化一下？ 思考题: 把fib_memo直接定义为memorize(fib)是否能提高计算效率？为什么？2.3 无需改动原函数实现记忆我们只需要利用Python中的装饰器(Decorator),就能达到不改动函数实现而能提升计算效率的效果。def memorize(f): memo = {} def inner(x): if x not in memo: memo[x] = f(x) return memo[x] return inner@memorizedef fib_memo_decorator(n): if n == 0: return 0 if n == 1: return 1 return fib_memo_decorator(n - 1) + fib_memo_decorator(n - 2)## fib_memo_decorator(30) time elapsed: 4.57430000000425e-053. 思考题的研究先说结论: memorize(fib)不能起到记忆效果！！！很多人可能觉得“你这写的都是啥玩意儿阿，一会儿自由变量一会儿lambda一会儿decorator的，传lambda和定义好的函数由啥区别啊,为什么定义好的函数不能直接传入memorize而要用decorator啊。”，别急，我们慢慢来。（以下内容可能有误，有大佬发现烦请指出)先画出memorize求值的环境模型。要区分fib_memo_lambda，decorator和fib_memo = memorize(fib),只需要将实际参数应用于上面这个环境模型中即可。3.1 fib_memo_lambda的求值过程def memorize(f):\tmemo = {}\tdef inner(n):\t\tif n not in memo:\t\t\tmemo[n] = f(n)\t\treturn memo[n]\treturn inner\tfib_memo_lambda = memorize(lambda x: 0 if x == 0 else 1 if x == 1 else fib_memo_lambda(x - 1) + fib_memo_lambda(x - 2))fib_memo_lambda绑定的环境如下图所示:从这里可以看出fib_memo_lambda绑定环境中的f其实是一个unnamed lambda,该unnamed lambda运算时会去递归的调用有记忆的fib_memo_lambda，该递归调用开销不大，因为我递归调用的是带记忆的过程。3.2 fib_memo_lambda = memorize(fib)无效的原因先上图，fib_memo_lambda=memorize(fib)的环境模型如下。可以看到memorize(fib)这里的unnamed lambda递归调用的其实是不带记忆的过程fib,那么memorize(fib)每次计算一个不在memo中的值的时候，就会进入到无记忆的fib当中去求值，其速度自然也就慢了。3.3 fib_memo_decorator有效的原因先看装饰器的定义： 装饰器语法只是一种语法糖，以下两个函数定义在语义上完全等价: def f(...): ...f = staticmethod(f)@staticmethoddef f(...): ... PEP对decorator的解释也就是说,以下两个语句完全等价@memorizedef fib_memo_decorator(n):fib_memo_decorator = memorize(fib_memo_decorator)这个过程中fib_memo_decorator发生了重新绑定。fib_memo_decorator在加装饰器前的样子：容易看出就是个普通的递归过程。执行fib_memo_decorator=memorize(fib_memo_decorator):虚线为fib_memo_decorator发生的第二次绑定。可以看出发生二次绑定后，inner内的f递归调用的也是带记忆的过程了。4. 总结懒得总结了，应该讲的很清楚了_(´ཀ`」 ∠)_。" } ]
